---
title: run
description: Start the Ralph TUI execution loop to autonomously process tasks from your tracker.
---

## Synopsis

```bash
ralph-tui run [options]
```

The `run` command starts the autonomous execution loop. Ralph will select tasks, build prompts, execute your AI agent, detect completion, and repeat until all tasks are done or the iteration limit is reached.

<Callout type="tip">
Running `ralph-tui` without any command also starts the TUI interface, allowing you to navigate and start execution interactively.
</Callout>

## Options

### Task Source Options

| Option | Description |
|--------|-------------|
| `--prd <path>` | PRD file path (auto-switches to json tracker) |
| `--epic <id>` | Epic ID for beads tracker |

### Agent & Model Options

| Option | Description |
|--------|-------------|
| `--agent <name>` | Override agent plugin (e.g., `claude`, `opencode`) |
| `--model <name>` | Override model (see [Model Options](#model-options) below) |
| `--tracker <name>` | Override tracker plugin (e.g., `beads`, `beads-bv`, `json`) |

### Execution Control

| Option | Description |
|--------|-------------|
| `--iterations <n>` | Maximum iterations (0 = unlimited) |
| `--delay <ms>` | Delay between iterations in milliseconds |
| `--serial`, `--sequential` | Force sequential execution (disable parallel) |
| `--parallel [N]` | Force parallel execution, optionally with N workers |

### Output & State

| Option | Description |
|--------|-------------|
| `--prompt <path>` | Custom prompt template file path |
| `--output-dir <path>` | Directory for iteration logs (default: `.ralph-tui/iterations`) |
| `--progress-file <path>` | Progress file for cross-iteration context (default: `.ralph-tui/progress.md`) |

### Display Options

| Option | Description |
|--------|-------------|
| `--headless` | Run without TUI (alias: `--no-tui`) |
| `--no-setup` | Skip interactive setup even if no config exists |

## Model Options

The `--model` flag accepts different values depending on which agent you're using.

### Claude Agent

```bash
ralph-tui run --agent claude --model <model>
```

| Model | Description |
|-------|-------------|
| `sonnet` | Claude Sonnet - balanced performance and cost |
| `opus` | Claude Opus - most capable, higher cost |
| `haiku` | Claude Haiku - fastest, lowest cost |

### OpenCode Agent

```bash
ralph-tui run --agent opencode --model <provider>/<model>
```

Models use `provider/model` format. Valid providers:

| Provider | Example Models |
|----------|----------------|
| `anthropic` | `anthropic/claude-3-5-sonnet`, `anthropic/claude-3-opus` |
| `openai` | `openai/gpt-4o`, `openai/gpt-4-turbo` |
| `google` | `google/gemini-pro`, `google/gemini-1.5-pro` |
| `xai` | `xai/grok-1` |
| `ollama` | `ollama/llama3`, `ollama/codellama` |

<Callout type="info">
Model names within each provider are validated by the provider's API. If you specify an invalid model name, you'll see an error from the underlying agent CLI.
</Callout>

## Examples

### Basic Usage with JSON Tracker

```bash
# Run with a prd.json file
ralph-tui run --prd ./prd.json

# Limit to 5 iterations
ralph-tui run --prd ./prd.json --iterations 5
```

### Using Beads Tracker

```bash
# Run with a beads epic
ralph-tui run --epic my-feature-epic

# Use beads-bv for intelligent task selection
ralph-tui run --epic my-feature-epic --tracker beads-bv
```

### Agent & Model Override

```bash
# Use Claude Opus for complex tasks
ralph-tui run --prd ./prd.json --agent claude --model opus

# Use OpenCode with GPT-4
ralph-tui run --prd ./prd.json --agent opencode --model openai/gpt-4o
```

### Custom Prompt Template

```bash
# Use a custom Handlebars template
ralph-tui run --prd ./prd.json --prompt ./my-template.hbs
```

### Headless Mode (CI/Scripts)

```bash
# Run without TUI for automation
ralph-tui run --prd ./prd.json --headless --iterations 10
```

### Development Workflow

```bash
# Add delay between iterations for monitoring
ralph-tui run --prd ./prd.json --delay 5000

# Custom output directory for logs
ralph-tui run --prd ./prd.json --output-dir ./logs/ralph
```

## Execution Flow

When you run this command, Ralph:

1. **Loads configuration** from `.ralph-tui/config.toml`
2. **Connects to tracker** (json, beads, or beads-bv)
3. **Selects next task** based on priority and dependencies
4. **Builds prompt** using the Handlebars template
5. **Spawns agent** with the prompt
6. **Streams output** to the TUI (or stdout in headless mode)
7. **Detects completion** via `<promise>COMPLETE</promise>` token
8. **Marks task done** and proceeds to next task
9. **Repeats** until no tasks remain or max iterations reached

## Session Persistence

Ralph automatically saves state to `.ralph-tui/session.json`:

- Current iteration number
- Task statuses
- Iteration history
- Active task IDs (for crash recovery)

If interrupted, use [`ralph-tui resume`](/docs/cli/resume) to continue.

## Remote Listener

Enable remote monitoring and control by adding the `--listen` flag. This starts a WebSocket server alongside the execution engine, allowing you to connect from another machine.

### Remote Options

| Option | Description |
|--------|-------------|
| `--listen` | Enable remote listener (WebSocket server) |
| `--listen-port <n>` | Port for remote listener (default: 7890) |
| `--rotate-token` | Rotate server token before starting |

### First Run: Token Generation

On first use of `--listen`, a secure authentication token is generated:

```
═══════════════════════════════════════════════════════════════
                   Server Authentication Token
═══════════════════════════════════════════════════════════════

  A new server token has been generated:

  OGQwNTcxMjM0NTY3ODkwYWJjZGVmMDEyMzQ1Njc4OQ

  ⚠️  IMPORTANT: This token is shown only once. Save it securely.
     You will need it to connect remote clients to this instance.

═══════════════════════════════════════════════════════════════
```

**Save this token securely!** You'll need it to configure remote clients.

### Examples

```bash
# Start with remote listener on default port (7890)
ralph-tui run --prd ./prd.json --listen

# Use custom port
ralph-tui run --epic my-feature --listen --listen-port 8080

# Rotate token and start (invalidates old connections)
ralph-tui run --prd ./prd.json --listen --rotate-token
```

### Connecting from Remote

After starting with `--listen`, connect from another machine:

```bash
# Add remote connection
ralph-tui remote add prod server.example.com:7890 --token <token>

# View remote in TUI
ralph-tui run
# Then press number keys to switch between local and remote tabs
```

### Security Model

Ralph uses a two-tier token system:

| Token Type | Lifetime | Purpose |
|------------|----------|---------|
| **Server Token** | 90 days | Initial authentication, stored on disk |
| **Connection Token** | 24 hours | Session authentication, auto-refreshed |

**Host binding:**
- Without `--listen`: binds to `127.0.0.1` (local only)
- With `--listen`: binds to `0.0.0.0` (network accessible, requires token auth)

### Audit Logging

All remote actions are logged to `~/.config/ralph-tui/audit.log`:

```jsonl
{"timestamp":"2026-01-19T15:30:00.000Z","clientId":"abc12345@192.168.1.100","action":"connection_connect","success":true}
{"timestamp":"2026-01-19T15:30:05.000Z","clientId":"abc12345@192.168.1.100","action":"pause","success":true}
```

## Parallel Execution

By default, ralph-tui analyzes task dependencies and automatically runs independent tasks in parallel when beneficial. Each parallel worker runs in its own git worktree for full isolation.

```bash
# Auto-detect (default) — parallel when beneficial
ralph-tui run --prd ./prd.json

# Force parallel with 4 workers
ralph-tui run --prd ./prd.json --parallel 4

# Force sequential (disable parallel)
ralph-tui run --prd ./prd.json --serial
```

When parallel mode is active, the TUI shows additional views:
- Press `w` to toggle the workers view
- Press `m` to toggle the merge progress view
- Press `Enter` on a worker to see its detail output

See the [Parallel Execution guide](/docs/parallel/overview) for full documentation.

## Related Commands

- **[resume](/docs/cli/resume)** - Continue an interrupted session
- **[status](/docs/cli/status)** - Check session status
- **[logs](/docs/cli/logs)** - View iteration output logs
- **[remote](/docs/cli/remote)** - Manage remote server connections
